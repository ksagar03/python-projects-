{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceClassifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    Con, img= cam.read()\n",
    "    if Con:\n",
    "        gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "        faces = faceClassifier.detectMultiScale(gray_image, 1.3, 10)\n",
    "        for x,y,w,h in faces:\n",
    "            img = cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        cv2.imshow(\"my face\", img)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        print(\"connect your camera..\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-j8nxabm_\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c84c3db9f7b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mCon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgray_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mCon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"My Cam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-j8nxabm_\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(2)\n",
    "while True:\n",
    "    Con, img = cam.read()\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if Con:\n",
    "        cv2.imshow(\"My Cam\", img)\n",
    "        cv2.imshow(\"Gray Cam\", gray_image)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break                                  ##not connected any external camera\n",
    "    else:\n",
    "        print(\"please connect your camera\")\n",
    "        \n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataSet():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    Sam = 0\n",
    "    while True:\n",
    "        Con, img = cam.read()\n",
    "        if Con:\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceClassifier.detectMultiScale(gray_image, 1.3, 6)\n",
    "            for x,y,w,h in faces:\n",
    "                face = gray_image[y:y+h, x:x+w]\n",
    "                face = cv2.resize(face, (150,150))\n",
    "                \n",
    "                \n",
    "                cv2.imwrite(\"Images/user.{}.jpg\".format(Sam), face)\n",
    "                Sam = Sam+1\n",
    "                face = cv2.putText(face,str(Sam), (30,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9,(0,255,0), 2)\n",
    "                cv2.imshow(\"my face\", face)\n",
    "                \n",
    "                \n",
    "            if Sam == 50:\n",
    "                print(\"we collected your ugly faces...\")\n",
    "                break\n",
    "                \n",
    "                \n",
    "            if cv2.waitKey(1)==13:\n",
    "               break\n",
    "    cam.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we collected your ugly faces...\n"
     ]
    }
   ],
   "source": [
    "CreateDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train ur model with ur faces.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    " \n",
    "path = \"Images/\"\n",
    "all_images = os.listdir(path)[:-1]\n",
    "\n",
    "\n",
    "training_data = []\n",
    "labels = np.arange(1, len(all_images)+1)\n",
    "labels = np.asarray(labels, dtype = np.int32)\n",
    "for i in all_images:\n",
    "    img_path = path + i\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Narray = np.asarray(image, dtype = np.uint8)\n",
    "    training_data.append(Narray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we trained ur machine with ur faces \n"
     ]
    }
   ],
   "source": [
    "Face_Model = cv2.face_LBPHFaceRecognizer.create()\n",
    "Face_Model.train(training_data, labels)\n",
    "print(\"we trained ur machine with ur faces \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 45.50340353251008)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        Con, img = cam.read()\n",
    "        if Con:\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceClassifier.detectMultiScale(gray_image, 1.3, 6)\n",
    "            for x,y,w,h in faces:\n",
    "                face = gray_image[y:y+h, x:x+w]\n",
    "                face = cv2.resize(face, (150,150))\n",
    "                \n",
    "                \n",
    "                pred = Face_Model.predict(face)\n",
    "                print(pred)\n",
    "                if pred[1]<42:\n",
    "                    face = cv2.putText(img,\"Hey! Sexy\", (x,y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9,(0,255,0), 2)\n",
    "                    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "                else:\n",
    "                    face = cv2.putText(img,\"unknown face\", (x,y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9,(0,0,255), 2)\n",
    "                    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "                    \n",
    "               \n",
    "            cv2.imshow(\"my face\", img)\n",
    "                \n",
    "            if cv2.waitKey(1)==13:\n",
    "               break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Face_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-db75853bba1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFace_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Face_Model' is not defined"
     ]
    }
   ],
   "source": [
    "    while True:\n",
    "        img = cv2.imread(\"arjuna.jpg\")\n",
    "        if True:\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceClassifier.detectMultiScale(gray_image, 1.3, 6)\n",
    "            for x,y,w,h in faces:\n",
    "                face = gray_image[y:y+h, x:x+w]\n",
    "                face = cv2.resize(face, (150,150))\n",
    "                \n",
    "                \n",
    "                pred = Face_Model.predict(face)\n",
    "                print(pred)\n",
    "                if pred[1]<100:\n",
    "                    face = cv2.putText(img,\"Hey! Sexy\", (x,y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9,(0,255,0), 2)\n",
    "                    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "                else:\n",
    "                    face = cv2.putText(img,\"unknown face\", (x,y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9,(0,0,255), 2)\n",
    "                    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "                    \n",
    "               \n",
    "            cv2.imshow(\"my face\", img)\n",
    "                \n",
    "            if cv2.waitKey(1)==13:\n",
    "               break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,6,7,6,5,4,5,6,7,8,3,4,5,3,2,1,3,4,5,5]\n",
    "y = [12,32,42,45,26,27,38,57,36,12,23,34,45,54,43,32,21,23,34,43,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 4., 0., 4., 6., 0., 3., 2., 1.]),\n",
       " array([1. , 1.7, 2.4, 3.1, 3.8, 4.5, 5.2, 5.9, 6.6, 7.3, 8. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 3., 2., 5., 2., 3., 2., 0., 2.]),\n",
       " array([12. , 16.5, 21. , 25.5, 30. , 34.5, 39. , 43.5, 48. , 52.5, 57. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-j8nxabm_\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1389: error: (-215:Assertion failed) scaleFactor > 1 && _image.depth() == CV_8U in function 'cv::CascadeClassifierImpl::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-59fe34b9d2e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgray_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaceClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgray_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-j8nxabm_\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1389: error: (-215:Assertion failed) scaleFactor > 1 && _image.depth() == CV_8U in function 'cv::CascadeClassifierImpl::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "gray_image = cv2.COLOR_BGR2GRAY\n",
    "faces = faceClassifier.detectMultiScale(gray_image, 1.3, 6)\n",
    "for x,y,w,h in faces:\n",
    "    face = gray_image[y:y+h, x:x+w]\n",
    "    face = cv2.resize(face, (150,150))\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"my face\")\n",
    "                \n",
    "    if cv2.waitKey(1)==13:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
